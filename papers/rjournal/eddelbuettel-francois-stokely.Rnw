% !TeX root = RJwrapper.tex
\title{RProtoBuf: Efficient Cross-Language Data Serialization in R}
\author{by Dirk Eddelbuettel, Romain Fran\c{c}ois, and Murray Stokely}

\maketitle

\abstract{Modern data collection and analysis pipelines often involve
 a sophisticated mix of applications written in general purpose and
 specialized programming languages.  Protocol Buffers are a popular
 method of serializing structured data between applications---while remaining
 independent of programming languages or operating system.  The
 \CRANpkg{RProtoBuf} package provides a complete interface to this
 library.
 %TODO(ms) keep it less than 150 words.
}

%TODO(de) 'protocol buffers' or 'Protocol Buffers' ?

\section{Introduction}

Modern data collection and analysis pipelines are increasingly being
built using collections of components to better manage software
complexity through reusability, modularity, and fault
isolation \citep{Wegiel:2010:CTT:1932682.1869479}.  Different
programming languages are often used for the different phases of data
analysis -- collection, cleaning, analysis, post-processing, and
presentation in order to take advantage of the unique combination of 
performance, speed of development, and library support offered by
different environments.  Each stage of the data
analysis pipeline may involve storing intermediate results in a
file or sending them over the network.  Programming langauges such as
Java, Ruby, Python, and R include built-in serialization support, but
these formats are tied to the specific programming language in use.
CSV files can be read and written by many applications and so are
often used for exporting tabular data.  However, CSV files have a
number of disadvantages, such as a limitation of exporting only
tabular datasets, lack of type-safety, inefficient text representation
and parsing, and abiguities in the format involving special
characters.  JSON is another widely supported format used mostly on
the web that removes many of these disadvantages, but it too suffers
from being too slow to parse and also does not provide strong typing
between integers and floating point.  Large numbers of JSON messages
would also be required to duplicate the field names with each message.

TODO(ms): Also work in reference to Split-Apply-Combine pattern for
data analysis \citep{wickham2011split}, since that is a great pattern
but it seems overly optimistic to expect all of those phases to always
be done in the same language.

This article describes the basics of Google's Protocol Buffers through
an easy to use R package, \CRANpkg{RProtoBuf}.  After describing the
basics of protocol buffers and \CRANpkg{RProtoBuf}, we illustrate
several common use cases for protocol buffers in data analysis.

\section{Protocol Buffers}

Once the data serialization needs get complex enough, application
developers typically benefit from the use of an \emph{interface
description language}, or \emph{IDL}.  IDLs like Google's Protocol
Buffers and Apache Thrift provide a compact well-documented schema for
cross-langauge data structures as well efficient binary interchange
formats.  The schema can be used to generate model classes for
statically typed programming languages such as C++ and Java, or can be
used with reflection for dynamically typed programming languages.
Since the schema is provided separately from the encoded data, the
data can be efficiently encoded to minimize storage costs of the
stored data when compared with simple ``schema-less'' binary
interchange formats like BSON.

%BSON, msgpack, Thrift, and Protocol Buffers take this latter approach,
%with the

% There are references comparing these we should use here.

TODO Also mention Thrift and msgpack and the references comparing some
of these tradeoffs.

Introductory section which may include references in parentheses
\citep{R}, or cite a reference such as \citet{R} in the text.

Protocol buffers are a language-neutral, platform-neutral, extensible
way of serializing structured data for use in communications
protocols, data storage, and more.

Protocol Buffers offer key features such as an efficient data interchange
format that is both language- and operating system-agnostic yet uses a
lightweight and highly performant encoding, object serialization and
de-serialization as well data and configuration management. Protocol
buffers are also forward compatible: updates to the \texttt{proto}
files do not break programs built against the previous specification.

While benchmarks are not available, Google states on the project page that in
comparison to XML, protocol buffers are at the same time \textsl{simpler},
between three to ten times \textsl{smaller}, between twenty and one hundred
times \textsl{faster}, as well as less ambiguous and easier to program.

The protocol buffers code is released under an open-source (BSD) license. The
protocol buffer project (\url{http://code.google.com/p/protobuf/})
contains a C++ library and a set of runtime libraries and compilers for
C++, Java and Python.

With these languages, the workflow follows standard practice of so-called
Interface Description Languages (IDL)
(c.f. \href{http://en.wikipedia.org/wiki/Interface_description_language}{Wikipedia
  on IDL}).  This consists of compiling a protocol buffer description file
(ending in \texttt{.proto}) into language specific classes that can be used
to create, read, write and manipulate protocol buffer messages. In other
words, given the 'proto' description file, code is automatically generated
for the chosen target language(s). The project page contains a tutorial for
each of these officially supported languages:
\url{http://code.google.com/apis/protocolbuffers/docs/tutorials.html}

Besides the officially supported C++, Java and Python implementations, several projects have been
created to support protocol buffers for many languages. The list of known
languages to support protocol buffers is compiled as part of the
project page: \url{http://code.google.com/p/protobuf/wiki/ThirdPartyAddOns}

The protocol buffer project page contains a comprehensive
description of the language: \url{http://code.google.com/apis/protocolbuffers/docs/proto.html}

\noindent
\begin{tabular}{@{}p{.40\textwidth}|p{0.5\textwidth}@{}}
\begin{minipage}{.35\textwidth}
\begin{example}
package tutorial;
message Person {
 required string name = 1;
 required int32 id = 2;
 optional string email = 3;
 enum PhoneType {
   MOBILE = 0; HOME = 1;
   WORK = 2;
 }
 message PhoneNumber {
   required string number = 1;
   optional PhoneType type = 2;
 }
 repeated PhoneNumber phone = 4;
}
\end{example}
\end{minipage} & \begin{minipage}{.45\textwidth}
<<echo=TRUE>>=
library(RProtoBuf)
person <- new(tutorial.Person, id=1,
              name="Romain")
person
person$name
person$name <- "Dirk"
cat(as.character(person))
@ 
\end{minipage}
\end{tabular}

%This section may contain a figure such as Figure~\ref{figure:rlogo}.
%
%\begin{figure}[htbp]
%  \centering
%  \includegraphics{Rlogo}
%  \caption{The logo of R.}
%  \label{figure:rlogo}
%\end{figure}

\section{Dynamic use: Protocol Buffers and R}

TODO(ms): random citations to work in:


Many sources compare data serialization formats and show protocol
buffers very favorably to the alternatives, such
as \citep{Sumaray:2012:CDS:2184751.2184810}

This section describes how to use the R API to create and manipulate
protocol buffer messages in R, and how to read and write the
binary \emph{payload} of the messages to files and arbitrary binary
R connections.

\subsection{Importing proto files}

In contrast to the other languages (Java, C++, Python) that are officially
supported by Google, the implementation used by the \texttt{RProtoBuf}
package does not rely on the \texttt{protoc} compiler (with the exception of
the two functions discussed in the previous section). This means that no
initial step of statically compiling the proto file into C++ code that is
then accessed by R code is necessary. Instead, \texttt{proto} files are
parsed and processed \textsl{at runtime} by the protobuf C++ library---which
is much more appropriate for a dynamic language.

The \texttt{readProtoFiles} function allows importing \texttt{proto}
files in several ways.

Using the \texttt{file} argument, one can specify one or several file
paths that ought to be proto files.

<<>>=
proto.dir <- system.file( "proto", package = "RProtoBuf" )
proto.file <- file.path( proto.dir, "addressbook.proto" )
<<eval=FALSE>>=
readProtoFiles( proto.file )
@

With the \texttt{dir} argument, which is
ignored if the \texttt{file} is supplied, all files matching the
\texttt{.proto} extension will be imported.

<<>>=
dir( proto.dir, pattern = "\\.proto$", full.names = TRUE )
<<eval=FALSE>>=
readProtoFiles( dir = proto.dir )
@

Finally, with the
\texttt{package} argument (ignored if \texttt{file} or
\texttt{dir} is supplied), the function will import all \texttt{.proto}
files that are located in the \texttt{proto} sub-directory of the given
package. A typical use for this argument is in the \texttt{.onLoad}
function of a package.

<<eval=FALSE>>=
readProtoFiles( package = "RProtoBuf" )
@

Once the proto files are imported, all message descriptors are
are available in the R search path in the \texttt{RProtoBuf:DescriptorPool}
special environment. The underlying mechanism used here is
described in more detail in section~\ref{sec-lookup}.

<<>>=
ls( "RProtoBuf:DescriptorPool" )
@


\subsection{Creating a message}

The objects contained in the special environment are
descriptors for their associated message types. Descriptors will be
discussed in detail in another part of this document, but for the
purpose of this section, descriptors are just used with the \texttt{new}
function to create messages.

<<>>=
p <- new( tutorial.Person, name = "Romain", id = 1 )
@

\subsection{Access and modify fields of a message}

Once the message is created, its fields can be queried
and modified using the dollar operator of R, making protocol
buffer messages seem like lists.

<<>>=
p$name
p$id
p$email <- "francoisromain@free.fr"
@

However, as opposed to R lists, no partial matching is performed
and the name must be given entirely.

The \verb|[[| operator can also be used to query and set fields
of a mesages, supplying either their name or their tag number :

<<>>=
p[["name"]] <- "Romain Francois"
p[[ 2 ]] <- 3
p[[ "email" ]]
@

Protocol buffers include a 64-bit integer type, but R lacks native
64-bit integer support.  A workaround is available and described in
Section~\ref{sec:int64} for working with large integer values.

% TODO(mstokely): Document extensions here.
% There are none in addressbook.proto though.

\subsection{Display messages}

Protocol buffer messages and descriptors implement \texttt{show}
methods that provide basic information about the message :

<<>>=
p
@

For additional information, such as for debugging purposes,
the \texttt{as.character} method provides a more complete ASCII
representation of the contents of a message.

<<>>=
writeLines( as.character( p ) )
@

\subsection{Serializing messages}

However, the main focus of protocol buffer messages is
efficiency. Therefore, messages are transported as a sequence
of bytes. The \texttt{serialize} method is implemented for
protocol buffer messages to serialize a message into the sequence of
bytes (raw vector in R speech) that represents the message.

<<>>=
serialize( p, NULL )
@

The same method can also be used to serialize messages to files :

<<>>=
tf1 <- tempfile()
tf1
serialize( p, tf1 )
readBin( tf1, raw(0), 500 )
@

Or to arbitrary binary connections:

<<>>=
tf2 <- tempfile()
con <- file( tf2, open = "wb" )
serialize( p, con )
close( con )
readBin( tf2, raw(0), 500 )
@

\texttt{serialize} can also be used in a more traditionnal
object oriented fashion using the dollar operator :

<<>>=
# serialize to a file
p$serialize( tf1 )
# serialize to a binary connection
con <- file( tf2, open = "wb" )
p$serialize( con )
close( con )
@


\subsection{Parsing messages}

The \texttt{RProtoBuf} package defines the \texttt{read}
function to read messages from files, raw vector (the message payload)
and arbitrary binary connections.

<<>>=
args( read )
@


The binary representation of the message (often called the payload)
does not contain information that can be used to dynamically
infer the message type, so we have to provide this information
to the \texttt{read} function in the form of a descriptor :

<<>>=
message <- read( tutorial.Person, tf1 )
writeLines( as.character( message ) )
@

The \texttt{input} argument of \texttt{read} can also be a binary
readable R connection, such as a binary file connection:

<<>>=
con <- file( tf2, open = "rb" )
message <- read( tutorial.Person, con )
close( con )
writeLines( as.character( message ) )
@

Finally, the payload of the message can be used :

<<>>=
# reading the raw vector payload of the message
payload <- readBin( tf1, raw(0), 5000 )
message <- read( tutorial.Person, payload )
@


\texttt{read} can also be used as a pseudo method of the descriptor
object :

<<>>=
# reading from a file
message <- tutorial.Person$read( tf1 )
# reading from a binary connection
con <- file( tf2, open = "rb" )
message <- tutorial.Person$read( con )
close( con )
# read from the payload
message <- tutorial.Person$read( payload )
@

\section{Basic Abstractions: Messages, Descriptors, and
  DescriptorPools}

The three basic abstractions of \CRANpkg{RProtoBuf} are Messages,
which encapsulate a data structure, Descriptors, which define the
schema used by one or more messages, and DescriptorPools, which
provide access to descriptors.

\section{Under the hood: S4 Classes, Methods, and Pseudo Methods}

The \CRANpkg{RProtoBuf} package uses the S4 system to store
information about descriptors and messages, but the information stored
in the R object is very minimal and mainly consists of an external
pointer to a C++ variable that is managed by the \texttt{protobuf} C++
library.

Using the S4 system allows the \texttt{RProtoBuf} package to dispatch
methods that are not generic in the S3 sense, such as \texttt{new} and
\texttt{serialize}.

The \texttt{RProtoBuf} package combines the \emph{R typical} dispatch
of the form \verb|method( object, arguments)| and the more traditional
object oriented notation \verb|object$method(arguments)|.

TODO(ms): Perhaps a table here of the different S4 classes, how many
methods they include, whether it dynamically does dispatch on other
strings, whether/how it is available in the search path, etc.

\subsection{Messages}

The \texttt{Message} S4 class represents Protocol Buffer Messages and
is the core abstraction of \CRANpkg{RProtoBuf}.  Each \texttt{Message}
has a \texttt{Descriptor} S4 class which defines the schema of the
data defined in the Message, as well as a number of
\texttt{FieldDescriptors} for the individual fields of the message.



represented in R using the \texttt{Message}
S4 class. The class contains the slots \texttt{pointer} and \texttt{type} as
described on the Table~\ref{Message-class-table}.

\section{Type Coercion}

\subsection{Booleans}
Bools
Int64s.

\subsection{64-bit integers}
\label{sec:int64}

R does not have native 64-bit integer support.  Instead, R treats
large integers as doubles which have limited precision.  For example,
it loses the ability to distinguish some distinct integers:

<<>>=
2^53 == (2^53 + 1)
@

Protocol Buffers are frequently used to pass data between different
systems, however, and most other systems these days have support for
64-bit integers.  To work around this, RProtoBuf allows users to get
and set 64-bit integer types by treating them as characters.

<<echo=FALSE,print=FALSE>>=
if (!exists("protobuf_unittest.TestAllTypes",
            "RProtoBuf:DescriptorPool")) {
    unittest.proto.file <- system.file("unitTests", "data",
                                       "unittest.proto",
                                       package="RProtoBuf")
    readProtoFiles(file=unittest.proto.file)
}
@

If we try to set an int64 field in R to double values, we lose
precision:

<<>>=
test <- new(protobuf_unittest.TestAllTypes)
test$repeated_int64 <- c(2^53, 2^53+1)
length(unique(test$repeated_int64))
@

However, we can specify the values as character strings so that the
C++ library on which RProtoBuf is based can store a true 64-bit
integer representation of the data.

<<>>=
test$repeated_int64 <- c("9007199254740992", "9007199254740993")
@

When reading the value back into R, numeric types are returned by
default, but when the full precision is required a character value
will be returned if the \texttt{RProtoBuf.int64AsString} option is set
to \texttt{TRUE}.

<<>>=
options("RProtoBuf.int64AsString" = FALSE)
test$repeated_int64
length(unique(test$repeated_int64))
options("RProtoBuf.int64AsString" = TRUE)
test$repeated_int64
length(unique(test$repeated_int64))
@

<<echo=FALSE,print=FALSE>>=
options("RProtoBuf.int64AsString" = FALSE)
@ 


\section{Related work on IDLs (greatly expanded from what you have)}

\section{Design tradeoffs: reflection vs proto compiler (not addressed
  at all in current vignettes)}

\subsection{Performance considerations}

TODO RProtoBuf is quite flexible and easy to use for interactive
analysis, but it is not designed for certain classes of operations one
might like to do with protocol buffers.  For example, taking a list of
10,000 protocol buffers, extracting a named field from each one, and
computing a aggregate statistics on those values would be extremely
slow with RProtoBuf, and while this is a useful class of operations,
it is outside of the scope of RProtoBuf.  We should be very clear
about this to clarify the goals and strengths of RProtoBuf and its
reflection and object mapping.

\subsection{Serialization comparison}

TODO comparison of protobuf serialization sizes/times for various vectors.  Compared to R's native serialization.  Discussion of the RHIPE approach of serializing any/all R objects, vs more specific protocol buffers for specific R objects.


\section{Descriptor lookup}
\label{sec-lookup}

The \texttt{RProtoBuf} package uses the user defined tables framework
that is defined as part of the \texttt{RObjectTables} package available
from the OmegaHat project \citep{RObjectTables}.

The feature allows \texttt{RProtoBuf} to install the
special environment \emph{RProtoBuf:DescriptorPool} in the R search path.
The environment is special in that, instead of being associated with a
static hash table, it is dynamically queried by R as part of R's usual
variable lookup. In other words, it means that when the R interpreter
looks for a binding to a symbol (foo) in its search path,
it asks to our package if it knows the binding "foo", this is then
implemented by the \texttt{RProtoBuf} package by calling an internal
method of the \texttt{protobuf} C++ library.

\section{Other approaches}

Saptarshi Guha wrote another package that deals with integration
of protocol buffer messages with R, taking a different angle :
serializing any R object as a message, based on a single catch-all
\texttt{proto} file.  Saptarshi's package is available at
\url{http://ml.stat.purdue.edu/rhipe/doc/html/ProtoBuffers.html}.

Jeroen Ooms took a similar approach influenced by Saptarshi in his
\pkg{RProtoBufUtils} package.  Unlike Saptarshi's package,
RProtoBufUtils depends on RProtoBuf for underlying message operations.
This package is available at
\url{https://github.com/jeroenooms/RProtoBufUtils}.

% Phillip Yelland wrote another implementation, currently proprietary,
% that has significant speed advantages when querying fields from a
% large number of protocol buffers, but is less user friendly for the
% basic cases documented here.

\section{Basic usage example - tutorial.Person}

\section{Application: distributed Data Collection with MapReduce}

We could describe a common MapReduce pattern of having the MR written
in another language output protocol buffers that are later pulled into
R.  There is some text about this in section 2 of
http://cran.r-project.org/web/packages/HistogramTools/vignettes/HistogramTools.pdf 

\section{Application: Sending/receiving Interaction With Servers}

Unlike Apache Thrift, Protocol Buffers do not include a concrete RPC
implementation.  However, serialized protocol buffers can trivially be
sent over TCP or integrated with a proprietary RPC system.  Combined
with an RPC system this means that one can interactively craft request
messages, send the serialized message to a remote server, read back a
response, and then parse the response protocol buffer interactively.

\section{Summary}

%Its pretty useful.  Murray to see if he can get approval to talk a
%tiny bit about how much its used at Google.

%This file is only a basic article template. For full details of \emph{The R Journal} style and information on how to prepare your article for submission, see the \href{http://journal.r-project.org/latex/RJauthorguide.pdf}{Instructions for Authors}.

\bibliography{eddelbuettel-francois-stokely}

\address{Dirk Eddelbuettel\\
  Debian and R Projects\\
  711 Monroe Avenue, River Forest, IL 60305\\
  USA}
\email{edd@debian.org}

\address{Author Two\\
  Affiliation\\
  Address\\
  Country}
\email{author2@work}

\address{Murray Stokely\\
  Google, Inc.\\
  1600 Amphitheatre Parkway\\
  Mountain View, CA 94043\\
  USA}
\email{mstokely@google.com}
