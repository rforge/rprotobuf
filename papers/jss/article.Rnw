\documentclass[article]{jss}
\usepackage{booktabs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% Local helpers to make this more compatible with R Journal style.
%
\newcommand{\CRANpkg}[1]{\pkg{#1}}
\RequirePackage{fancyvrb}
\RequirePackage{alltt}
\DefineVerbatimEnvironment{example}{Verbatim}{}

%% almost as usual
\author{Dirk Eddelbuettel\\Debian Project \And 
        Murray Stokely\\Google, Inc \And
        Jeroen Ooms\\UCLA}
\title{\pkg{RProtoBuf}: Efficient Cross-Language Data Serialization in R}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Dirk Eddelbuettel, Murray Stokely, Jeroen Ooms} %% comma-separated
\Plaintitle{RProtoBuf: Efficient Cross-Language Data Serialization in R}
\Shorttitle{\pkg{RProtoBuf}: Protocol Buffers in R} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
Modern data collection and analysis pipelines often involve
a sophisticated mix of applications written in general purpose and
specialized programming languages.  Protocol Buffers are a popular
method of serializing structured data between applications---while remaining
independent of programming languages or operating system.  The
\CRANpkg{RProtoBuf} package provides a complete interface between this
library and the R environment for statistical computing.
%TODO(ms) keep it less than 150 words.
}
\Keywords{r, protocol buffers, serialization, cross-platform}
\Plainkeywords{r, protocol buffers, serialization, cross-platform} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Dirk Eddelbuettel \\
  Debian Project \\
  River Forest, IL, USA\\
  E-mail: \email{edd@debian.org}\\
  URL: \url{http://dirk.eddelbuettel.com}\\
  \\
  Murray Stokely\\
  Google, Inc.\\
  1600 Amphitheatre Parkway\\
  Mountain View, CA 94040\\
  USA\\
  E-mail: \email{mstokely@google.com}\\
  URL: \url{http://www.stokely.org/}\\
  \\
  Jeroen Ooms\\
  UCLA Department of Statistics\\
  University of California\\
  E-mail: \email{jeroen.ooms@stat.ucla.edu}\\
  URL: \url{http://jeroenooms.github.io}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\SweaveOpts{concordance=FALSE}


%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.


% We don't want a left margin for Sinput or Soutput for our table 1.
%\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=0em}
%\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=0em}
%\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em}
% Setting the topsep to 0 reduces spacing from input to output and
% improves table 1.
\fvset{listparameters={\setlength{\topsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}

\title{RProtoBuf: Efficient Cross-Language Data Serialization in R}
\author{by Dirk Eddelbuettel and Murray Stokely}

%% DE: I tend to have wider option(width=...) so this
%%     guarantees better line breaks
<<echo=FALSE,print=FALSE>>=
options(width=65, prompt="R> ", digits=4)
@

\maketitle

%TODO(de) 'protocol buffers' or 'Protocol Buffers' ?

\section{Introduction}

Modern data collection and analysis pipelines are increasingly being
built using collections of components to better manage software
complexity through reusability, modularity, and fault
isolation \citep{Wegiel:2010:CTT:1932682.1869479}.
Data analysis patterns such as Split-Apply-Combine
\citep{wickham2011split} explicitly break up large problems into
manageable pieces.  These patterns are frequently employed with
different programming languages used for the different phases of data
analysis -- collection, cleaning, modeling, analysis, post-processing, and
presentation in order to take advantage of the unique combination of
performance, speed of development, and library support offered by
different environments and languages.  Each stage of such a data
analysis pipeline may involve storing intermediate results in a
file or sending them over the network.

Given these requirements, how do we safely share intermediate results
between different applications, possibly written in different
languages, and possibly running on different computer system, possibly
spanning different operating systems?  Programming
languages such as R, Julia, Java, and Python include built-in
serialization support, but these formats are tied to the specific
% DE: need to define serialization?
programming language in use and thus lock the user into a single
environment.  

\emph{Comma-separated values} (CSV) files can be read and written by many
applications and so are often used for exporting tabular data.  However, CSV
files have a number of disadvantages, such as a limitation of exporting only
tabular datasets, lack of type-safety, inefficient text representation and
parsing, possibly limited precision and ambiguities in the format involving
special characters.  \emph{JavaScript Object Notation} (JSON) is another
widely-supported format used mostly on the web that removes many of these
disadvantages, but it too suffers from being too slow to parse and also does
not provide strong typing between integers and floating point.  Because the
schema information is not kept separately, multiple JSON messages of the same
type needlessly duplicate the field names with each message.  Lastly,
\emph{Extensible Markup Language} (XML) is a well-established and widely-supported
protocol with the ability to define just about any arbitrarily complex
schema. However, it pays for this complexity with comparatively large and
verbose messages, and added complexities at the parsing side (which are
somewhat metigated by the availability of mature libraries and
parsers).

A number of binary formats based on JSON have been proposed that
reduce the parsing cost and improve the efficiency.  MessagePack
and BSON both have R interfaces, but % \citep{msgpackR,rmongodb}, but
% DE Why do we cite these packages, but not the numerous JSON packages?
these formats lack a separate schema for the serialized data and thus
still duplicate field names with each message sent over the network or
stored in a file.  Such formats also lack support for versioning when
data storage needs evolve over time, or when application logic and
requirement changes dictate update to the message format.

Once the data serialization needs of an application become complex
enough, developers typically benefit from the use of an
\emph{interface description language}, or \emph{IDL}.  IDLs like
Protocol Buffers \citep{protobuf}, Apache Thrift, and Apache Avro provide a compact
well-documented schema for cross-langauge data structures and
efficient binary interchange formats.  The schema can be used to
generate model classes for statically-typed programming languages such
as C++ and Java, or can be used with reflection for dynamically-typed
programming languages.  Since the schema is provided separately from
the encoded data, the data can be efficiently encoded to minimize
storage costs of the stored data when compared with simple
``schema-less'' binary interchange formats.
Many sources compare data serialization formats and show Protocol
Buffers very favorably to the alternatives; see
\citet{Sumaray:2012:CDS:2184751.2184810} for one such comparison.

% TODO(mstokely): Take a more conversational tone here asking
% questions and motivating protocol buffers?

% TODO(mstokely): If we go to JSS, include a larger paragraph here
% referencing each numbered section.  I don't like these generally,
% but its useful for this paper I think because we have a boring bit
% in the middle (full class/method details) and interesting
% applications at the end.

The rest of the paper is organized as follows. Section~\ref{sec:protobuf}
provides a general overview of Protocol Buffers.
Section~\ref{sec:rprotobuf-basic} describes the interactive R interface
provided by \CRANpkg{RProtoBuf} and introduces the two main abstractions:
\emph{Messages} and \emph{Descriptors}.  Section~\ref{sec:rprotobuf-classes}
describes the implementation details of the main S4 classes making up this
package.  Section~\ref{sec:types} describes the challenges of type coercion
between R and other languages.  Section~\ref{sec:evaluation} introduces a
general R language schema for serializing arbitrary R objects and evaluates
it against R's built-in serialization.  Sections~\ref{sec:opencpu}
and \ref{sec:mapreduce} provide real-world use cases of \CRANpkg{RProtoBuf}
in web service and MapReduce environments, respectively, before
Section~\ref{sec:summary} concludes.

%This article describes the basics of Google's Protocol Buffers through
%an easy to use R package, \CRANpkg{RProtoBuf}.  After describing the
%basics of protocol buffers and \CRANpkg{RProtoBuf}, we illustrate
%several common use cases for protocol buffers in data analysis.

\section{Protocol Buffers}
\label{sec:protobuf}

%FIXME Introductory section which may include references in parentheses
%\citep{R}, or cite a reference such as \citet{R} in the text.

% This content is good.  Maybe use and cite?
% http://martin.kleppmann.com/2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html

%% TODO(de,ms)  What follows is oooooold and was lifted from the webpage
%%              Rewrite?
Protocol Buffers can be described as a modern, language-neutral, platform-neutral,
extensible mechanism for sharing and storing structured data.  Since their
introduction, Protocol Buffers have been widely adopted in industry with
applications as varied as %database-internal messaging (Drizzle), % DE: citation?
Sony Playstations, Twitter, Google Search, Hadoop, and Open Street Map.  
% TODO(DE): This either needs a citation, or remove the name drop
While traditional IDLs have at time been criticized for code bloat and
complexity, Protocol Buffers are based on a simple list and records
model that is compartively flexible and simple to use.

Some of the key features provided by Protocol Buffers for data analysis
include:

\begin{itemize}
\item \emph{Portable}:  Enable users to send and receive data between
  applications as well as different computers or operating systems.
\item \emph{Efficient}:  Data is serialized into a compact binary
  representation for transmission or storage.
\item \emph{Extensible}:  New fields can be added to Protocol Buffer Schemas
  in a forward-compatible way that does not break older applications.
\item \emph{Stable}:  Protocol Buffers have been in wide use for over a
  decade.
\end{itemize}

Figure~\ref{fig:protobuf-distributed-usecase} illustrates an example
communication workflow with Protocol Buffers and an interactive R session.
Common use cases include populating a request remote-procedure call (RPC)
Protocol Buffer in R that is then serialized and sent over the network to a
remote server.  The server would then deserialize the message, act on the
request, and respond with a new Protocol Buffer over the network. The key
difference to, say, a request to an Rserve instance is that the remote server
may not even know the R language.

%Protocol buffers are a language-neutral, platform-neutral, extensible
%way of serializing structured data for use in communications
%protocols, data storage, and more.

%Protocol Buffers offer key features such as an efficient data interchange
%format that is both language- and operating system-agnostic yet uses a
%lightweight and highly performant encoding, object serialization and
%de-serialization as well data and configuration management. Protocol
%buffers are also forward compatible: updates to the \texttt{proto}
%files do not break programs built against the previous specification.

%While benchmarks are not available, Google states on the project page that in
%comparison to XML, protocol buffers are at the same time \textsl{simpler},
%between three to ten times \textsl{smaller}, between twenty and one hundred
%times \textsl{faster}, as well as less ambiguous and easier to program.

%The flexibility of the reflection-based API is particularly well
%suited for interactive data analysis.

% XXX Design tradeoffs: reflection vs proto compiler

For added speed and efficiency, the C++, Java, and Python bindings to
Protocol Buffers are used with a compiler that translates a Protocol
Buffer schema description file (ending in \texttt{.proto}) into
language-specific classes that can be used to create, read, write and
manipulate Protocol Buffer messages.  The R interface, in contrast,
uses a reflection-based API that is particularly well-suited for
interactive data analysis.  All messages in R have a single class
structure, but different accessor methods are created at runtime based
on the name fields of the specified message type.

% In other words, given the 'proto'
%description file, code is automatically generated for the chosen
%target language(s). The project page contains a tutorial for each of
%these officially supported languages:
%\url{http://code.google.com/apis/protocolbuffers/docs/tutorials.html}

%The protocol buffers code is released under an open-source (BSD) license. The
%protocol buffer project (\url{http://code.google.com/p/protobuf/})
%contains a C++ library and a set of runtime libraries and compilers for
%C++, Java and Python.

%With these languages, the workflow follows standard practice of so-called
%Interface Description Languages (IDL)
%(c.f. \href{http://en.wikipedia.org/wiki/Interface_description_language}{Wikipedia
%  on IDL}).  This consists of compiling a protocol buffer description file
%(ending in \texttt{.proto}) into language specific classes that can be used

%Besides the officially supported C++, Java and Python implementations, several projects have been
%created to support protocol buffers for many languages. The list of known
%languages to support protocol buffers is compiled as part of the
%project page: \url{http://code.google.com/p/protobuf/wiki/ThirdPartyAddOns}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{protobuf-distributed-system-crop.pdf}
\end{center}
\caption{Example protobuf usage}
\label{fig:protobuf-distributed-usecase}
\end{figure}

\section{Basic Usage: Messages and Descriptors}
\label{sec:rprotobuf-basic}

This section describes how to use the R API to create and manipulate
protocol buffer messages in R, and how to read and write the
binary \emph{payload} of the messages to files and arbitrary binary
R connections.

The two fundamental building blocks of Protocol Buffers are \emph{Messages}
and \emph{Descriptors}.  Messages provide a common abstract encapsulation of
structured data fields of the type specified in a Message Descriptor.
Message Descriptors are defined in \texttt{.proto} files and define a
schema for a particular named class of messages.

Table~\ref{tab:proto} shows an example \texttt{.proto} file which
defines the \texttt{tutorial.Person} type.  The R code in the right
column shows an example of creating a new message of this type and
populating its fields.

% Commented out because we said this earlier.
%This separation
%between schema and the message objects is in contrast to
%more verbose formats like JSON, and when combined with the efficient
%binary representation of any Message object explains a large part of
%the performance and storage-space advantage offered by Protocol
%Buffers. TODO(ms): we already said some of this above.  clean up.

% lifted from protobuf page:
%With Protocol Buffers you define how you want your data to be
%structured once, and then you can read or write structured data to and
%from a variety of data streams using a variety of different
%languages.  The definition


%% TODO(de) Can we make this not break the width of the page?
\noindent
\begin{table}
\begin{tabular}{p{.40\textwidth}p{0.55\textwidth}}
\toprule
Schema : \texttt{addressbook.proto} & Example R Session\\
\cmidrule{1-2}
\begin{minipage}{.40\textwidth}
\vspace{2mm}
\begin{example}
package tutorial;
message Person {
 required string name = 1;
 required int32 id = 2;
 optional string email = 3;
 enum PhoneType {
   MOBILE = 0; HOME = 1;
   WORK = 2;
 }
 message PhoneNumber {
   required string number = 1;
   optional PhoneType type = 2;
 }
 repeated PhoneNumber phone = 4;
}
\end{example}
\vspace{2mm}
\end{minipage} & \begin{minipage}{.55\textwidth}
<<echo=TRUE>>=
library(RProtoBuf)
p <- new(tutorial.Person,id=1,name="Dirk")
class(p)
p$name
p$name <- "Murray"
cat(as.character(p))
serialize(p, NULL)
@
\end{minipage} \\
\bottomrule
\end{tabular}
\caption{The schema representation from a \texttt{.proto} file for the
  \texttt{tutorial.Person} class (left) and simple R code for creating
  an object of this class and accessing its fields (right).}
\label{tab:proto}
\end{table}

%This section may contain a figure such as Figure~\ref{figure:rlogo}.
%
%\begin{figure}[htbp]
%  \centering
%  \includegraphics{Rlogo}
%  \caption{The logo of R.}
%  \label{figure:rlogo}
%\end{figure}

\subsection{Importing Message Descriptors from .proto files}

%The three basic abstractions of \CRANpkg{RProtoBuf} are Messages,
%which encapsulate a data structure, Descriptors, which define the
%schema used by one or more messages, and DescriptorPools, which
%provide access to descriptors.

To create or parse a Protocol Buffer Message, one must first read in 
the message type specification from a \texttt{.proto} file. The 
\texttt{.proto} files are imported using the \code{readProtoFiles}
function, which can either import a single file, all files in a directory,
or every \texttt{.proto} file provided by a particular R package.
The \texttt{.proto} file syntax for defining the structure of protocol
buffer data is described comprehensively on Google Code\footnote{See 
\url{http://code.google.com/apis/protocolbuffers/docs/proto.html}.}.

After importing proto files, the corresponding message descriptors are
available from the \texttt{RProtoBuf:DescriptorPool} environment in 
the R search path. The underlying mechanism used here is
described in more detail in Section~\ref{sec-lookup}.

%JO: can we just move the section 7 to here? It's only one paragraph%

<<>>=
ls("RProtoBuf:DescriptorPool")
@

%\subsection{Importing proto files}
%In contrast to the other languages (Java, C++, Python) that are officially
%supported by Google, the implementation used by the \texttt{RProtoBuf}
%package does not rely on the \texttt{protoc} compiler (with the exception of
%the two functions discussed in the previous section). This means that no
%initial step of statically compiling the proto file into C++ code that is
%then accessed by R code is necessary. Instead, \texttt{proto} files are
%parsed and processed \textsl{at runtime} by the protobuf C++ library---which
%is much more appropriate for a dynamic language.

\subsection{Creating a message}

New messages are created with the \texttt{new} function which accepts
a Message Descriptor and optionally a list of ``name = value'' pairs
to set in the message.
%The objects contained in the special environment are
%descriptors for their associated message types. Descriptors will be
%discussed in detail in another part of this document, but for the
%purpose of this section, descriptors are just used with the \texttt{new}
%function to create messages.

<<>>=
p1 <- new(tutorial.Person)
p <- new(tutorial.Person, name = "Murray", id = 1)
@

\subsection{Access and modify fields of a message}

Once the message is created, its fields can be queried
and modified using the dollar operator of R, making protocol
buffer messages seem like lists.

<<>>=
p$name
p$id
p$email <- "murray@stokely.org"
@

However, as opposed to R lists, no partial matching is performed
and the name must be given entirely.
The \verb|[[| operator can also be used to query and set fields
of a messages, supplying either their name or their tag number :

<<>>=
p[["name"]] <- "Murray Stokely"
p[[ 2 ]] <- 3
p[[ "email" ]]
@

Protocol Buffers include a 64-bit integer type, but R lacks native
64-bit integer support.  A workaround is available and described in
Section~\ref{sec:int64} for working with large integer values.

% TODO(mstokely): Document extensions here.
% There are none in addressbook.proto though.

\subsection{Display messages}

Protocol Buffer messages and descriptors implement \texttt{show}
methods that provide basic information about the message :

<<>>=
p
@

For additional information, such as for debugging purposes,
the \texttt{as.character} method provides a more complete ASCII
representation of the contents of a message.

<<>>=
writeLines(as.character(p))
@

\subsection{Serializing messages}

However, the main focus of Protocol Buffer messages is
efficiency. Therefore, messages are transported as a sequence
of bytes. The \texttt{serialize} method is implemented for
Protocol Buffer messages to serialize a message into a sequence of
bytes that represents the message.
%(raw vector in R speech) that represents the message.

<<>>=
serialize(p, NULL)
@

The same method can be used to serialize messages to files :

<<>>=
tf1 <- tempfile()
serialize(p, tf1)
readBin(tf1, raw(0), 500)
@

Or to arbitrary binary connections:

<<>>=
tf2 <- tempfile()
con <- file(tf2, open = "wb")
serialize(p, con)
close(con)
readBin(tf2, raw(0), 500)
@

\texttt{serialize} can also be called in a more traditional
object oriented fashion using the dollar operator:

<<>>=
# serialize to a file
p$serialize(tf1)
# serialize to a binary connection
con <- file(tf2, open = "wb")
p$serialize(con)
close(con)
@


\subsection{Parsing messages}

The \texttt{RProtoBuf} package defines the \texttt{read} and
\texttt{readASCII} functions to read messages from files, raw vectors,
or arbitrary connections.  \texttt{read} expects to read the message
payload from binary files or connections and \texttt{readASCII} parses
the human-readable ASCII output that is created with
\code{as.character}.

The binary representation of the message (often called the payload)
does not contain information that can be used to dynamically
infer the message type, so we have to provide this information
to the \texttt{read} function in the form of a descriptor :

<<>>=
msg <- read(tutorial.Person, tf1)
writeLines(as.character(msg))
@

The \texttt{input} argument of \texttt{read} can also be a binary
readable R connection, such as a binary file connection:

<<>>=
con <- file(tf2, open = "rb")
message <- read(tutorial.Person, con)
close(con)
writeLines(as.character(message))
@

Finally, the payload of the message can be used :

<<>>=
# reading the raw vector payload of the message
payload <- readBin(tf1, raw(0), 5000)
message <- read(tutorial.Person, payload)
@


\texttt{read} can also be used as a pseudo-method of the descriptor
object :

<<>>=
# reading from a file
message <- tutorial.Person$read(tf1)
# reading from a binary connection
con <- file(tf2, open = "rb")
message <- tutorial.Person$read(con)
close(con)
# read from the payload
message <- tutorial.Person$read(payload)
@


\section{Under the hood: S4 Classes, Methods, and Pseudo Methods}
\label{sec:rprotobuf-classes}

The \CRANpkg{RProtoBuf} package uses the S4 system to store
information about descriptors and messages.  Using the S4 system
allows the \texttt{RProtoBuf} package to dispatch methods that are not
generic in the S3 sense, such as \texttt{new} and
\texttt{serialize}.

Each R object stores an external pointer to an object managed by
the \texttt{protobuf} C++ library which implements the core Protocol Buffer
functionality.  The \CRANpkg{Rcpp} package
\citep{eddelbuettel2011rcpp,eddelbuettel2013seamless} is used to 
facilitate the integration of the R and C++ code for these objects.

% Message, Descriptor, FieldDescriptor, EnumDescriptor,
% FileDescriptor, EnumValueDescriptor
%
% grep RPB_FUNC * | grep -v define|wc -l
% 84
% grep RPB_ * | grep -v RPB_FUNCTION | grep METHOD|wc -l
% 33

There are over 100 C++ functions that provide the glue code between
the member functions of the 6 primary Message and Descriptor classes
in the protobuf library.  Wrapping each method individually allows us
to add user friendly custom error handling, type coercion, and
performance improvements at the cost of a more verbose
implementation.  The RProtoBuf implementation in many ways motivated
the development of Rcpp Modules \citep{eddelbuettel2013exposing},
which provide a more concise way of wrapping C++ functions and classes
in a single entity.

The \texttt{RProtoBuf} package combines a functional dispatch mechanism 
of the form \verb|method(object, arguments)| (common to R) and the more
traditional object oriented notation \verb|object$method(arguments)|.
Additionally, \texttt{RProtoBuf} implements the \texttt{.DollarNames} S3 generic function
(defined in the \texttt{utils} package) for all classes to enable tab
completion.  Completion possibilities include pseudo-method names for all
classes, plus dynamic dispatch on names or types specific to a given object.

% TODO(ms): Add column check box for doing dynamic dispatch based on type.
\begin{table}[h]
\centering
\begin{tabular}{lccl}
\toprule
\textbf{Class}      & 
     \textbf{Slots} & 
     \textbf{Methods} & 
     \textbf{Dynamic Dispatch}\\
\cmidrule{1-4}
Message             & 2 & 20 & yes (field names)\\
Descriptor          & 2 & 16 & yes (field names, enum types, nested types)\\
FieldDescriptor     & 4 & 18 & no\\
EnumDescriptor      & 4 & 11 & yes (enum constant names)\\
FileDescriptor      & 3 & \phantom{1}6 & yes (message/field definitions)\\
EnumValueDescriptor & 3 & \phantom{1}6 & no\\
\bottomrule
\end{tabular}
\caption{\label{Message-methods-table}Overview of Class, Slot, Method and
  Dispatch Relationships}
\end{table}

\subsection{Messages}

The \texttt{Message} S4 class represents Protocol Buffer Messages and
is the core abstraction of \CRANpkg{RProtoBuf}. Each \texttt{Message}
contains a pointer to a \texttt{Descriptor} which defines the schema
of the data defined in the Message, as well as a number of
\texttt{FieldDescriptors} for the individual fields of the message.  A
complete list of the slots and methods for \texttt{Messages}
is available in Table~\ref{Message-methods-table}.

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & External pointer to the \texttt{Message} object of the C++ protobuf library. Documentation for the
\texttt{Message} class is available from the Protocol Buffer project page. \\
%(\url{http://code.google.com/apis/protocolbuffers/docs/reference/cpp/google.protobuf.message.html#Message}) \\
\texttt{type} & Fully qualified name of the message. For example a \texttt{Person} message
has its \texttt{type} slot set to \texttt{tutorial.Person} \\[.3cm]
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{has} & Indicates if a message has a given field.   \\
\texttt{clone} & Creates a clone of the message \\
\texttt{isInitialized} & Indicates if a message has all its required fields set\\
\texttt{serialize} & serialize a message to a file, binary connection, or raw vector\\
\texttt{clear} & Clear one or several fields of a message, or the entire message\\
\texttt{size} & The number of elements in a message field\\
\texttt{bytesize} & The number of bytes the message would take once serialized\\[3mm]
%
\texttt{swap} & swap elements of a repeated field of a message\\
\texttt{set} & set elements of a repeated field\\
\texttt{fetch} & fetch elements of a repeated field\\
\texttt{setExtension} & set an extension of a message\\
\texttt{getExtension} & get the value of an extension of a message\\
\texttt{add} & add elements to a repeated field \\[3mm]
%
\texttt{str} & the R structure of the message\\
\texttt{as.character} & character representation of a message\\
\texttt{toString} & character representation of a message (same as \texttt{as.character}) \\
\texttt{as.list} & converts message to a named R list\\
\texttt{update} & updates several fields of a message at once\\
\texttt{descriptor} & get the descriptor of the message type of this message\\
\texttt{fileDescriptor} & get the file descriptor of this message's descriptor\\
\hline
\end{tabular}
\end{small}
\caption{\label{Message-methods-table}Description of slots and methods for the \texttt{Message} S4 class}
\end{table}

\subsection{Descriptors}

Descriptors describe the type of a Message.  This includes what fields
a message contains and what the types of those fields are.  Message
descriptors are represented in R with the \emph{Descriptor} S4
class. The class contains the slots \texttt{pointer} and
\texttt{type}.  Similarly to messages, the \verb|$| operator can be
used to retrieve descriptors that are contained in the descriptor, or
invoke pseudo-methods.

When \CRANpkg{RProtoBuf} is first loaded it calls
\texttt{readProtoFiles} to read in an example \texttt{.proto} file
included with the package.  The \texttt{tutorial.Person} descriptor
and any other descriptors defined in loaded \texttt{.proto} files are
then available on the search path.

<<>>=
# field descriptor
tutorial.Person$email

# enum descriptor
tutorial.Person$PhoneType

# nested type descriptor
tutorial.Person$PhoneNumber
# same as
tutorial.Person.PhoneNumber
@

Table~\ref{Descriptor-methods-table} provides a complete list of the
slots and available methods for Descriptors.

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & External pointer to the \texttt{Descriptor} object of the C++ proto library. Documentation for the
\texttt{Descriptor} class is available from the Protocol Buffer project page.\\
%\url{http://code.google.com/apis/protocolbuffers/docs/reference/cpp/google.protobuf.descriptor.html#Descriptor} \\
\texttt{type} & Fully qualified path of the message type. \\[.3cm]
%
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{new} & Creates a prototype of a message described by this descriptor.\\
\texttt{read} & Reads a message from a file or binary connection.\\
\texttt{readASCII} & Read a message in ASCII format from a file or
text connection.\\
\texttt{name} & Retrieve the name of the message type associated with
this descriptor.\\
\texttt{as.character} & character representation of a descriptor\\
\texttt{toString} & character representation of a descriptor (same as \texttt{as.character}) \\
\texttt{as.list} & return a named
list of the field, enum, and nested descriptors included in this descriptor.\\
\texttt{asMessage} & return DescriptorProto message. \\
\texttt{fileDescriptor} & Retrieve the file descriptor of this
descriptor.\\
\texttt{containing\_type} & Retrieve the descriptor describing the message type containing this descriptor.\\
\texttt{field\_count} & Return the number of fields in this descriptor.\\
\texttt{field} & Return the descriptor for the specified field in this descriptor.\\
\texttt{nested\_type\_count} & The number of nested types in this descriptor.\\
\texttt{nested\_type} & Return the descriptor for the specified nested 
type in this descriptor.\\
\texttt{enum\_type\_count} & The number of enum types in this descriptor.\\
\texttt{enum\_type} & Return the descriptor for the specified enum
type in this descriptor.\\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{Descriptor-methods-table}Description of slots and methods for the \texttt{Descriptor} S4 class}
\end{table}

\subsection{Field Descriptors}
\label{subsec-field-descriptor}

The class \emph{FieldDescriptor} represents field
descriptor in R. This is a wrapper S4 class around the
\texttt{google::protobuf::FieldDescriptor} C++ class.
Table~\ref{fielddescriptor-methods-table} describes the methods
defined for the \texttt{FieldDescriptor} class.

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & External pointer to the \texttt{FieldDescriptor} C++ variable \\
\texttt{name} & Simple name of the field \\
\texttt{full\_name} & Fully qualified name of the field \\
\texttt{type} & Name of the message type where the field is declared \\[.3cm]
%
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{as.character} & Character representation of a descriptor\\
\texttt{toString} & Character representation of a descriptor (same as \texttt{as.character}) \\
\texttt{asMessage} & Return FieldDescriptorProto message. \\
\texttt{name} & Return the name of the field descriptor.\\
\texttt{fileDescriptor} & Return the fileDescriptor where this field is defined.\\
\texttt{containing\_type} & Return the containing descriptor of this field.\\
\texttt{is\_extension} & Return TRUE if this field is an extension.\\
\texttt{number} & Gets the declared tag number of the field.\\
\texttt{type} & Gets the type of the field.\\
\texttt{cpp\_type} & Gets the C++ type of the field.\\
\texttt{label} & Gets the label of a field (optional, required, or repeated).\\
\texttt{is\_repeated} & Return TRUE if this field is repeated.\\
\texttt{is\_required} & Return TRUE if this field is required.\\
\texttt{is\_optional} & Return TRUE if this field is optional.\\
\texttt{has\_default\_value} & Return TRUE if this field has a default value.\\
\texttt{default\_value} & Return the default value.\\
\texttt{message\_type} & Return the message type if this is a message type field.\\
\texttt{enum\_type} & Return the enum type if this is an enum type field.\\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{fielddescriptor-methods-table}Description of slots and
  methods for the \texttt{FieldDescriptor} S4 class}
\end{table}

% TODO(ms): Useful distinction to make -- FieldDescriptor does not do
% separate '$' dispatch like Messages, Descriptors, and
% EnumDescriptors do.  Should it?

\subsection{Enum Descriptors}
\label{subsec-enum-descriptor}

The class \emph{EnumDescriptor} is an R wrapper
class around the C++ class \texttt{google::protobuf::EnumDescriptor}.
Table~\ref{enumdescriptor-methods-table} describes the methods
defined for the \texttt{EnumDescriptor} class.

The \verb|$| operator can be used to retrieve the value of enum
constants contained in the EnumDescriptor, or to invoke
pseudo-methods.

<<>>=
tutorial.Person$PhoneType
tutorial.Person$PhoneType$WORK
@

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & External pointer to the \texttt{EnumDescriptor} C++ variable \\
\texttt{name} & Simple name of the enum \\
\texttt{full\_name} & Fully qualified name of the enum \\
\texttt{type} & Name of the message type where the enum is declared \\[.3cm]
%
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{as.list} & return a named
integer vector with the values of the enum and their names.\\
\texttt{as.character} & character representation of a descriptor\\
\texttt{toString} & character
representation of a descriptor (same as \texttt{as.character}) \\
\texttt{asMessage} & return EnumDescriptorProto message. \\
\texttt{name} & Return the name of the enum descriptor.\\
\texttt{fileDescriptor} & Return the fileDescriptor where this field is defined.\\
\texttt{containing\_type} & Return the containing descriptor of this field.\\
\texttt{length} & Return the number of constants in this enum.\\
\texttt{has} & Return TRUE if this enum contains the specified named constant string.\\
\texttt{value\_count} & Return the number of constants in this enum (same as \texttt{length}).\\
\texttt{value} & Return the EnumValueDescriptor of an enum value of specified index, name, or number.\\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{enumdescriptor-methods-table}Description of slots and methods for the \texttt{EnumDescriptor} S4 class}
\end{table}

\subsection{File Descriptors}
\label{subsec-file-descriptor}

The class \emph{FileDescriptor} is an R wrapper
class around the C++ class \texttt{google::protobuf::FileDescriptor}.
Table~\ref{filedescriptor-methods-table} describes the methods
defined for the \texttt{FileDescriptor} class.

The \verb|$| operator can be used to retrieve named fields defined in
the FileDescriptor, or to invoke pseudo-methods.

<<>>=
f <- tutorial.Person$fileDescriptor()
f
f$Person
@

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & external pointer to the \texttt{FileDescriptor} object of the C++ proto library. Documentation for the
\texttt{FileDescriptor} class is available from the protocol buffer project page:
\url{http://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.descriptor.html#FileDescriptor} \\
\texttt{filename} & fully qualified pathname of the \texttt{.proto} file.\\
\texttt{package} & package name defined in this \texttt{.proto} file.\\[.3cm]
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{name} & Return the filename for this FileDescriptorProto.\\
\texttt{package} & Return the file-level package name specified in this FileDescriptorProto.\\
\texttt{as.character} & character representation of a descriptor. \\
\texttt{toString} & character representation of a descriptor (same as \texttt{as.character}). \\
\texttt{asMessage} & return FileDescriptorProto message. \\
\texttt{as.list} & return named list of descriptors defined in this file descriptor.\\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{filedescriptor-methods-table}Description of slots and methods for the \texttt{FileDescriptor} S4 class}
\end{table}

\subsection{Enum Value Descriptors}
\label{subsec-enumvalue-descriptor}

The class \emph{EnumValueDescriptor} is an R wrapper
class around the C++ class \texttt{google::protobuf::EnumValueDescriptor}.
Table~\ref{EnumValueDescriptor-methods-table} describes the methods
defined for the \texttt{EnumValueDescriptor} class.

The \verb|$| operator can be used to invoke pseudo-methods.

<<>>=
tutorial.Person$PhoneType$value(1)
tutorial.Person$PhoneType$value(name="HOME")
tutorial.Person$PhoneType$value(number=1)
@

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Slot} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{pointer} & External pointer to the \texttt{EnumValueDescriptor} C++ variable \\
\texttt{name} & simple name of the enum value \\
\texttt{full\_name} & fully qualified name of the enum value \\[.3cm]
%
\textbf{Method} & \textbf{Description} \\
\cmidrule(r){2-2}
\texttt{number} & return the number of this EnumValueDescriptor. \\
\texttt{name} & Return the name of the enum value descriptor.\\
\texttt{enum\_type} & return the EnumDescriptor type of this EnumValueDescriptor. \\
\texttt{as.character} & character representation of a descriptor. \\
\texttt{toString} & character representation of a descriptor (same as \texttt{as.character}). \\
\texttt{asMessage} & return EnumValueDescriptorProto message. \\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{EnumValueDescriptor-methods-table}Description of slots
  and methods for the \texttt{EnumValueDescriptor} S4 class}
\end{table}

\section{Type Coercion}
\label{sec:types}

One of the benefits of using an Interface Definition Language (IDL)
like Protocol Buffers is that it provides a highly portable basic type
system. This permits different language and hardware implementations to map to
the most appropriate type in different environments.

Table~\ref{table-get-types} details the correspondence between the
field type and the type of data that is retrieved by \verb|$| and \verb|[[|
extractors.

\begin{table}[h]
\centering
\begin{small}
\begin{tabular}{lp{5cm}p{5cm}}
\toprule
Field type & R type (non repeated) & R type (repeated) \\
\cmidrule(r){2-3}
double	& \texttt{double} vector & \texttt{double} vector \\
float	& \texttt{double} vector & \texttt{double} vector \\[3mm]
uint32	  & \texttt{double} vector & \texttt{double} vector \\
fixed32	  & \texttt{double} vector & \texttt{double} vector \\[3mm]
int32	  & \texttt{integer} vector & \texttt{integer} vector \\
sint32	  & \texttt{integer} vector & \texttt{integer} vector \\
sfixed32  & \texttt{integer} vector & \texttt{integer} vector \\[3mm]
int64	  & \texttt{integer} or \texttt{character}
vector    & \texttt{integer} or \texttt{character} vector \\
uint64	  & \texttt{integer} or \texttt{character} vector & \texttt{integer} or \texttt{character} vector \\
sint64	  & \texttt{integer} or \texttt{character} vector & \texttt{integer} or \texttt{character} vector \\
fixed64	  & \texttt{integer} or \texttt{character} vector & \texttt{integer} or \texttt{character} vector \\
sfixed64  & \texttt{integer} or \texttt{character} vector & \texttt{integer} or \texttt{character} vector \\[3mm]
bool	& \texttt{logical} vector & \texttt{logical} vector \\[3mm]
string	& \texttt{character} vector & \texttt{character} vector \\
bytes	& \texttt{character} vector & \texttt{character} vector \\[3mm]
enum & \texttt{integer} vector & \texttt{integer} vector \\[3mm]
message & \texttt{S4} object of class \texttt{Message} & \texttt{list} of \texttt{S4} objects of class \texttt{Message} \\
\bottomrule
\end{tabular}
\end{small}
\caption{\label{table-get-types}Correspondence between field type and
  R type retrieved by the extractors. Note that R lacks native
  64-bit integers, so the \texttt{RProtoBuf.int64AsString} option is
  available to return large integers as characters to avoid losing
  precision.  This option is described in Section~\ref{sec:int64}.}
\end{table}

\subsection{Booleans}

R booleans can accept three values: \texttt{TRUE}, \texttt{FALSE}, and
\texttt{NA}.  However, most other languages, including the Protocol
Buffer schema, only accept \texttt{TRUE} or \texttt{FALSE}.  This means
that we simply can not store R logical vectors that include all three
possible values as booleans.  The library will refuse to store
\texttt{NA}s in protocol buffer boolean fields, and users must instead
choose another type (such as enum or integer) capable of storing three
distinct values.

<<echo=FALSE,print=FALSE>>=
    if (!exists("protobuf_unittest.TestAllTypes",
                "RProtoBuf:DescriptorPool")) {
        unittest.proto.file <- system.file("unitTests", "data",
                                           "unittest.proto",
                                           package="RProtoBuf")
        readProtoFiles(file=unittest.proto.file)
    }
@

<<>>=
a <- new(protobuf_unittest.TestAllTypes)
a$optional_bool <- TRUE
a$optional_bool <- FALSE
<<eval=FALSE>>=
a$optional_bool <- NA
<<echo=FALSE,eval=TRUE,print=TRUE>>=
try(a$optional_bool <- NA,silent=TRUE)
@

\subsection{Unsigned Integers}

R lacks a native unsigned integer type.  Values between $2^{31}$ and
$2^{32} - 1$ read from unsigned into Protocol Buffer fields must be
stored as doubles in R.

<<>>=
as.integer(2^31-1)
<<eval=FALSE>>=
as.integer(2^31 - 1) + as.integer(1)
<<echo=FALSE,eval=TRUE,print=TRUE>>=
try(as.integer(2^31 - 1) + as.integer(1))

2^31
class(2^31)
@

\subsection{64-bit integers}
\label{sec:int64}

R does not have native 64-bit integer support.  Instead, R treats
large integers as doubles which have limited precision.  For example,
it loses the ability to distinguish some distinct integers:

<<>>=
2^53 == (2^53 + 1)
@

Protocol Buffers are frequently used to pass data between different
systems, however, and most other modern systems do have support for
64-bit integers.  To work around this, RProtoBuf allows users to get
and set 64-bit integer types by treating them as characters.

<<echo=FALSE,print=FALSE>>=
if (!exists("protobuf_unittest.TestAllTypes",
            "RProtoBuf:DescriptorPool")) {
    unittest.proto.file <- system.file("unitTests", "data",
                                       "unittest.proto",
                                       package="RProtoBuf")
    readProtoFiles(file=unittest.proto.file)
}
@

If we try to set an int64 field in R to double values, we lose
precision:

<<>>=
test <- new(protobuf_unittest.TestAllTypes)
test$repeated_int64 <- c(2^53, 2^53+1)
length(unique(test$repeated_int64))
@

However, we can specify the values as character strings so that the
C++ library on which RProtoBuf is based can store a true 64-bit
integer representation of the data.

<<>>=
test$repeated_int64 <- c("9007199254740992", "9007199254740993")
@

When reading the value back into R, numeric types are returned by
default, but when the full precision is required a character value
will be returned if the \texttt{RProtoBuf.int64AsString} option is set
to \texttt{TRUE}.  The character values are useful because they can
accurately be used as unique identifiers and can easily be passed to R
packages such as \CRANpkg{int64} \citep{int64} or \CRANpkg{bit64}
\citep{bit64} which represent 64-bit integers in R.

<<>>=
options("RProtoBuf.int64AsString" = FALSE)
test$repeated_int64
length(unique(test$repeated_int64))
options("RProtoBuf.int64AsString" = TRUE)
test$repeated_int64
length(unique(test$repeated_int64))
@

<<echo=FALSE,print=FALSE>>=
options("RProtoBuf.int64AsString" = FALSE)
@

\section{Evaluation: data.frame to Protocol Buffer Serialization}
\label{sec:evaluation}

The \pkg{RHIPE} package \citep{rhipe} also includes a Protocol integration with R.
However, its implementation takes a different approach: any R object is
serialized into a message based on a single catch-all \texttt{proto} schema.
A similar approach was taken by \pkg{RProtoBufUtils} package (which has now been integrated in
\pkg{RProtoBuf}). Unlike \pkg{RHIPE}, however, \pkg{RProtoBufUtils}
depended upon on, and extended, \pkg{RProtoBuf} for underlying message operations.
%DE Shall this go away now that we sucket RPBUtils into RBP?

One key extension which \pkg{RProtoBufUtils} brought to \pkg{RProtoBuf} is the 
\texttt{serialize\_pb} method to convert R objects into serialized
Protocol Buffers in the catch-all schema. The \texttt{can\_serialize\_pb}
method can then be used to determine whether the given R object can safely
be expressed in this way.  To illustrate how this method works, we
attempt to convert all of the built-in datasets from R into this
serialized Protocol Buffer representation.

<<echo=TRUE>>=
datasets <- subset(as.data.frame(data()$results), Package=="datasets")
datasets$load.name <- sub("\\s+.*$", "", datasets$Item)
n <- nrow(datasets)
@

There are \Sexpr{n} standard data sets included in R.  We use the
\texttt{can\_serialize\_pb} method to determine how many of those can
be safely converted to a serialized Protocol Buffer representation.

<<echo=TRUE>>=
datasets$valid.proto <- sapply(datasets$load.name,
                        function(x) can_serialize_pb(eval(as.name(x))))
datasets <- subset(datasets, valid.proto==TRUE)
m <- nrow(datasets)
@

\Sexpr{m} data sets could be converted to Protocol Buffers
(\Sexpr{format(100*m/n,digits=1)}\%).  The next section illustrates how
many bytes were used to store the data sets under four different
situations:
\begin{itemize}
\item normal R serialization,
\item R serialization followed by gzip,
\item normal Protocol Buffer serialization, and
\item Protocol Buffer serialization followed by gzip.
\end{itemize}

\subsection{Compression Performance}
\label{sec:compression}

<<echo=FALSE,print=FALSE>>=
datasets$object.size <- unname(sapply(datasets$load.name, function(x) object.size(eval(as.name(x)))))

datasets$R.serialize.size <- unname(sapply(datasets$load.name, function(x) length(serialize(eval(as.name(x)), NULL))))

datasets$R.serialize.size <- unname(sapply(datasets$load.name, function(x) length(serialize(eval(as.name(x)), NULL))))

datasets$R.serialize.size.gz <- unname(sapply(datasets$load.name, function(x) length(memCompress(serialize(eval(as.name(x)), NULL), "gzip"))))

datasets$RProtoBuf.serialize.size <- unname(sapply(datasets$load.name, function(x) length(serialize_pb(eval(as.name(x)), NULL))))

datasets$RProtoBuf.serialize.size.gz <- unname(sapply(datasets$load.name, function(x) length(memCompress(serialize_pb(eval(as.name(x)), NULL), "gzip"))))

clean.df <- data.frame(dataset=datasets$load.name,
                       object.size=datasets$object.size,
                       "serialized"=datasets$R.serialize.size,
                       "gzipped serialized"=datasets$R.serialize.size.gz,
                       "RProtoBuf"=datasets$RProtoBuf.serialize.size,
                       "gzipped RProtoBuf"=datasets$RProtoBuf.serialize.size.gz,
                       check.names=FALSE)
@

Table~\ref{tab:compression} shows the sizes of 50 sample R datasets as
returned by object.size() compared to the serialized sizes.
%The summary compression sizes are listed below, and a full table for a
%sample of 50 datasets is included on the next page.  
Sizes are comparable but Protocol Buffers provide simple getters and setters
in multiple languages instead of requiring other programs to parse the R
serialization format.% \citep{serialization}.
One takeaway from this table is that RProtoBuf does not in general provide
any significant saving in file size compared to the normal serialization
mechanism in R which is seen as equally compact.  The benefit from RProtoBuf
comes from its interoperability with other environments, as well as its safe
versioning,

TODO comparison of protobuf serialization sizes/times for various vectors.
Compared to R's native serialization.  Discussion of the RHIPE approach of
serializing any/all R objects, vs more specific Protocol Buffers for specific
R objects.

% N.B. see table.Rnw for how this table is created.
%
% latex table generated in R 3.0.2 by xtable 1.7-0 package
% Fri Dec 27 17:00:03 2013
\begin{table}[h!]
\begin{center}
  \small
\scalebox{0.9}{
\begin{tabular}{lrrrrr}
  \toprule
  Data Set & object.size & \multicolumn{2}{c}{R Serialization} &
  \multicolumn{2}{c}{RProtoBuf Serial.} \\
  & & default & gzipped & default & gzipped \\
  \cmidrule(r){2-6}
  uspop & 584 & 268 & 172 & 211 & 148 \\
  Titanic & 1960 & 633 & 257 & 481 & 249 \\
  volcano & 42656 & 42517 & 5226 & 42476 & 4232 \\
  euro.cross & 2728 & 1319 & 910 & 1207 & 891 \\
  attenu & 14568 & 8234 & 2165 & 7771 & 2336 \\
  ToothGrowth & 2568 & 1486 & 349 & 1239 & 391 \\
  lynx & 1344 & 1028 & 429 & 971 & 404 \\
  nottem & 2352 & 2036 & 627 & 1979 & 641 \\
  sleep & 2752 & 746 & 282 & 483 & 260 \\
  co2 & 4176 & 3860 & 1473 & 3803 & 1453 \\
  austres & 1144 & 828 & 439 & 771 & 410 \\
  ability.cov & 1944 & 716 & 357 & 589 & 341 \\
  EuStockMarkets & 60664 & 59785 & 21232 & 59674 & 19882 \\
  treering & 64272 & 63956 & 17647 & 63900 & 17758 \\
  freeny.x & 1944 & 1445 & 1311 & 1372 & 1289 \\
  Puromycin & 2088 & 813 & 306 & 620 & 320 \\
  warpbreaks & 2768 & 1231 & 310 & 811 & 343 \\
  BOD & 1088 & 334 & 182 & 226 & 168 \\
  sunspots & 22992 & 22676 & 6482 & 22620 & 6742 \\
  beaver2 & 4184 & 3423 & 751 & 3468 & 840 \\
  anscombe & 2424 & 991 & 375 & 884 & 352 \\
  esoph & 5624 & 3111 & 548 & 2240 & 665 \\
  PlantGrowth & 1680 & 646 & 303 & 459 & 314 \\
  infert & 15848 & 14328 & 1172 & 13197 & 1404 \\
  BJsales & 1632 & 1316 & 496 & 1259 & 465 \\
  stackloss & 1688 & 917 & 293 & 844 & 283 \\
  crimtab & 7936 & 4641 & 713 & 1655 & 576 \\
  LifeCycleSavings & 6048 & 3014 & 1420 & 2825 & 1407 \\
  Harman74.cor & 9144 & 6056 & 2045 & 5861 & 2070 \\
  nhtemp & 912 & 596 & 240 & 539 & 223 \\
  faithful & 5136 & 4543 & 1339 & 4936 & 1776 \\
  freeny & 5296 & 2465 & 1518 & 2271 & 1507 \\
  discoveries & 1232 & 916 & 199 & 859 & 180 \\
  state.x77 & 7168 & 4251 & 1754 & 4068 & 1756 \\
  pressure & 1096 & 498 & 277 & 427 & 273 \\
  fdeaths & 1008 & 692 & 291 & 635 & 272 \\
  euro & 976 & 264 & 186 & 202 & 161 \\
  LakeHuron & 1216 & 900 & 420 & 843 & 404 \\
  mtcars & 6736 & 3798 & 1204 & 3633 & 1206 \\
  precip & 4992 & 1793 & 813 & 1615 & 815 \\
  state.area & 440 & 422 & 246 & 405 & 235 \\
  attitude & 3024 & 1990 & 544 & 1920 & 561 \\
  randu & 10496 & 9794 & 8859 & 10441 & 9558 \\
  state.name & 3088 & 844 & 408 & 724 & 415 \\
  airquality & 5496 & 4551 & 1241 & 2874 & 1294 \\
  airmiles & 624 & 308 & 170 & 251 & 148 \\
  quakes & 33112 & 32246 & 9898 & 29063 & 11595 \\
  islands & 3496 & 1232 & 563 & 1098 & 561 \\
  OrchardSprays & 3600 & 2164 & 445 & 1897 & 483 \\
  WWWusage & 1232 & 916 & 274 & 859 & 251 \\
  \bottomrule
\end{tabular}
}
\caption{Serialization sizes for default serialization in R and
  RProtoBuf for 50 R datasets.}
\label{tab:compression}
\end{center}
\end{table}

\subsection{Performance considerations}

TODO RProtoBuf is quite flexible and easy to use for interactive
analysis, but it is not designed for certain classes of operations one
might like to do with Protocol Buffers.  For example, taking a list of
10,000 Protocol Buffers, extracting a named field from each one, and
computing a aggregate statistics on those values would be extremely
slow with RProtoBuf, and while this is a useful class of operations,
it is outside of the scope of RProtoBuf.  We should be very clear
about this to clarify the goals and strengths of RProtoBuf and its
reflection and object mapping.


\section{Descriptor lookup}
\label{sec-lookup}

The \texttt{RProtoBuf} package uses the user defined tables framework
that is defined as part of the \texttt{RObjectTables} package available
from the OmegaHat project \citep{RObjectTables}.

The feature allows \texttt{RProtoBuf} to install the
special environment \emph{RProtoBuf:DescriptorPool} in the R search path.
The environment is special in that, instead of being associated with a
static hash table, it is dynamically queried by R as part of R's usual
variable lookup. In other words, it means that when the R interpreter
looks for a binding to a symbol (foo) in its search path,
it asks to our package if it knows the binding "foo", this is then
implemented by the \texttt{RProtoBuf} package by calling an internal
method of the \texttt{protobuf} C++ library.

%\section{Other approaches}

% Phillip Yelland wrote another implementation, currently proprietary,
% that has significant speed advantages when querying fields from a
% large number of protocol buffers, but is less user friendly for the
% basic cases documented here.

%\section{Basic usage example - tutorial.Person}

\section{Application: Data Interchange in Web Services}
\label{sec:opencpu}

% TODO(jeroen): I think maybe some of this should go earlier in the
% paper, so this part can focus only on introducing the application,
% Can you integrate some of this text earlier, maybe into the the
% introduction?

As described earlier, the primary application of Protocol Buffers is data
interchange in the context of inter-system communications.  Network protocols
such as HTTP provide mechanisms for client-server communication, i.e. how to
initiate requests, authenticate, send messages, etc.  However, many network
protocols generally do not regulate the \emph{content} of messages: they
allow transfer of any media type, such as web pages, static files or
multimedia content.  When designing systems where various components require
exchange of specific data structures, we need something on top of the network
protocol that prescribes how these structures are to be represented in
messages (buffers) on the network. Protocol Buffers solve exactly this
problem by providing a cross-platform method for serializing arbitrary
structures into well defined messages, which can then be exchanged using any
protocol. The descriptors (\texttt{.proto} files) are used to formally define
the interface of a remote API or network application. Libraries to parse and
generate protobuf messages are available for many programming languages,
making it relatively straightforward to implement clients and servers.

\subsection{Interacting with R through HTTPS and Protocol Buffers}

One example of a system that supports Protocol Buffers to interact
with R is OpenCPU \citep{opencpu}. OpenCPU is a framework for embedded statistical 
computation and reproducible research based on R and \LaTeX. It exposes a 
HTTP(S) API to access and manipulate R objects and allows for performing 
remote R function calls. Clients do not need to understand 
or generate any R code: HTTP requests are automatically mapped to 
function calls, and arguments/return values can be posted/retrieved
using several data interchange formats, such as protocol buffers.  
OpenCPU uses the \texttt{serialize\_pb} and \texttt{unserialize\_pb} functions
from the \texttt{RProtoBuf} package to convert between R objects and protobuf
messages. Therefore, clients need the \texttt{rexp.proto} descriptor mentioned
earlier to parse and generate protobuf messages when interacting with OpenCPU.

\subsection{HTTP GET: Retrieving an R object}

The \texttt{HTTP GET} method is used to read a resource from OpenCPU. For example,
to access the dataset \texttt{Animals} from the package \texttt{MASS}, a 
client performs the following HTTP request:

\begin{verbatim}
  GET https://public.opencpu.org/ocpu/library/MASS/data/Animals/pb
\end{verbatim}
The postfix \texttt{/pb} in the URL tells the server to send this
object in the form of a protobuf message. Alternative formats include 
\texttt{/json}, \texttt{/csv}, \texttt{/rds} and others. If the request
is successful, OpenCPU returns the serialized object with HTTP status 
code 200 and HTTP response header \texttt{Content-Type: application/x-protobuf}. 
The latter is the conventional MIME type that formally notifies the client to
interpret the response as a protobuf message. 

Because both HTTP and Protocol Buffers have libraries available for many 
languages, clients can be implemented in just a few lines of code. Below
is example code for both R and Python that retrieves a dataset from R with 
OpenCPU using a protobuf message. In R, we use the HTTP client from 
the \texttt{httr} package \citep{httr}.
% superfluous?
%, and the protobuf parser from the \texttt{RProtoBuf} package.
In this example we
download a dataset which is part of the base R distribution, so we can
verify that the object was transferred without loss of information.

<<eval=FALSE>>=
# Load packages
library(RProtoBuf)
library(httr)

# Retrieve and parse message
req <- GET('https://public.opencpu.org/ocpu/library/MASS/data/Animals/pb')
output <- unserialize_pb(req$content)

# Check that no information was lost
identical(output, MASS::Animals)
@

This code suggests a method for exchanging objects between R servers, however this can 
also be done without Protocol Buffers. The main advantage of using an inter-operable format 
is that we can actually access R objects from within another
programming language. For example, in a very similar fashion we can retrieve the same
dataset in a Python client. To parse messages in Python, we first compile the 
\texttt{rexp.proto} descriptor into a python module using the \texttt{protoc} compiler:

\begin{verbatim}
  protoc rexp.proto --python_out=.
\end{verbatim}
This generates Python module called \texttt{rexp\_pb2.py}, containing both the 
descriptor information as well as methods to read and manipulate the R object 
message. In the example below we use the HTTP client from the \texttt{urllib2}
module. 

\begin{verbatim}
# Import modules
import urllib2
from rexp_pb2 import REXP

# Retrieve message
req = urllib2.Request('https://public.opencpu.org/ocpu/library/MASS/data/Animals/pb')
res = urllib2.urlopen(req)
        
# Parse rexp.proto message
msg = REXP()
msg.ParseFromString(res.read())
print(msg)
\end{verbatim}
The \texttt{msg} object contains all data from the Animals dataset. From here we
can easily extract the desired fields for further use in Python.


\subsection{HTTP POST: Calling an R function}

The example above shows how the \texttt{HTTP GET} method retrieves a 
resource from OpenCPU, for example an R object. The \texttt{HTTP POST} 
method on the other hand is used for calling functions and running scripts, 
which is the primary purpose of the framework. As before, the \texttt{/pb} 
postfix requests to retrieve the output as a protobuf message, in this
case the function return value. However, OpenCPU allows us to supply the
arguments of the function call in the form of protobuf messages as well.
This is a bit more work, because clients needs to both generate messages 
containing R objects to post to the server, as well as retrieve and parse
protobuf messages returned by the server. Using Protocol Buffers to post
function arguments is not required, and for simple (scalar) arguments 
the standard \texttt{application/x-www-form-urlencoded} format might be sufficient.
However, with protocol buffers the client can perform function calls with
more complex arguments such as R vectors or lists. The result is a complete
RPC system to do arbitrary R function calls from within 
any programming language.

The following example R client code performs the remote function call 
\texttt{stats::rnorm(n=42, mean=100)}. The function arguments (in this
case \texttt{n} and \texttt{mean}) as well as the return value (a vector
with 42 random numbers) are transferred using a protobuf message. RPC in
OpenCPU works like the \texttt{do.call} function in R, hence all arguments
are contained within a list.

<<eval=FALSE>>=
#requires httr >= 0.2.99
library(httr)
library(RProtoBuf)

args <- list(n=42, mean=100)
payload <- serialize_pb(args, NULL)

req <- POST (
  url = "https://public.opencpu.org/ocpu/library/stats/R/rnorm/pb",
  body = payload,
  add_headers (
    "Content-Type" = "application/x-protobuf"
  )
)

#This is the output of stats::rnorm(n=42, mean=100)
output <- unserialize_pb(req$content)
print(output)
@
The OpenCPU server basically performs the following steps to process the above RPC request:  

<<eval=FALSE>>=
fnargs <- unserialize_pb(inputmsg)
val <- do.call(stats::rnorm, fnargs)
outputmsg <- serialize_pb(val)
@

OpenCPU also provides a lot of meta-functionality such as handling
of sessions, exceptions, security, and more. OpenCPU also makes it possible to store
output of a function call on the server, instead of directly retrieving it. Thereby 
objects can be shared with other users or used as arguments in a subsequent
function call. But in its essence, the HTTP API provides a simple way to perform remote 
R function calls over HTTPS. The same request can be performed in Python as follows:

\begin{verbatim}
import urllib2;
from rexp_pb2 import *;

#create the post payload, i.e. list(n=42, mean=100)
payload = REXP(
  rclass = 5,
    rexpValue = [
      REXP(rclass = 2, realValue = [42]), 
      REXP(rclass = 2, realValue = [100])
    ],
    attrName = [
      "names"
    ],
    attrValue = [
      REXP(rclass = 0, stringValue = [STRING(strval="n"), STRING(strval="mean")])
    ]
);

#HTTP POST
req = urllib2.Request(
  "https://public.opencpu.org/ocpu/library/stats/R/rnorm/pb", 
  data = payload.SerializeToString(), 
  headers = {
    'Content-type': 'application/x-protobuf'
  }
)
res = urllib2.urlopen(req);
        
#parse output pb
msg = REXP();
msg.ParseFromString(res.read());

#the return value is a double vector in this case
print(msg.realValue);
\end{verbatim}

\section{Application: Distributed Data Collection with MapReduce}
\label{sec:mapreduce}

The MapReduce programming model \citep{dean2008mapreduce} has emerged
in the last decade as a popular framework for processing large data
sets in parallel on large compute clusters.  Protocol Buffers
provide a convenient mechanism to send structured data between tasks
in a MapReduce cluster.  In particular, the large data sets in fields
such as particle physics and information processing are frequently
stored in binned or histogram form in order to reduce the data storage
requirements for later data analysis \citep{scott2009multivariate}.

In such environments, analysts may be interested in very rare
phenomenon or be dealing with highly skewed data sets or inflexible
raw data storage systems from which unbiased sampling is not feasible.
There are two common patterns for generating histograms of large data
sets in a single pass with MapReduce.  In the first method, each
mapper task generates a histogram over a subset of the data that it
has been assigned, serializes this histogram and sends it to one or
more reducer tasks which merge the intermediate histograms from the
mappers.

In the second method, illustrated in
Figure~\ref{fig:mr-histogram-pattern1}, each mapper rounds a data
point to a bucket width and outputs that bucket as a key and '1' as a
value.  Reducers then sum up all of the values with the same key and
output to a data store.

In both methods, the mapper tasks must choose identical bucket
boundaries in advance if we are to construct the histogram in a single
pass, even though they are analyzing disjoint parts of the input set
that may cover different ranges.  The \pkg{HistogramTools} package
\citep{histogramtools} enhances \pkg{RProtoBuf} by providing a concise
schema for R histogram objects.  The histogram message type is
designed to be helpful if some of the Map or Reduce tasks are written
in R, or if those components are written in other languages and only
the resulting output histograms need to be manipulated in R.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{histogram-mapreduce-diag1.pdf}
\end{center}
\caption{Diagram of MapReduce Histogram Generation Pattern}
\label{fig:mr-histogram-pattern1}
\end{figure}

%\section{Application: Sending/receiving Interaction With Servers}
%
%Combined
%with an RPC system this means that one can interactively craft request
%messages, send the serialized message to a remote server, read back a
%response, and then parse the response protocol buffer interactively.

%TODO(mstokely): Talk about Jeroen Ooms OpenCPU, or talk about Andy
%Chu's Poly.


\section{Summary}
\label{sec:summary}

% RProtoBuf has been used.

%Its pretty useful.  Murray to see if he can get approval to talk a
%tiny bit about how much its used at Google.

%This file is only a basic article template. For full details of \emph{The R Journal} style and information on how to prepare your article for submission, see the \href{http://journal.r-project.org/latex/RJauthorguide.pdf}{Instructions for Authors}.

\section{Acknowledgement}

The first versions of \CRANpkg{RProtoBuf} were written during 2009-2010.
Very significant contributions, both in code and design, were made by
Romain Fran\c{c}ois whose continued influence on design and code is
greatly appreciated. Several features of the package are influenced
by the design of the \CRANpkg{rJava} package by Simon Urbanek
The user-defined table mechanism, implemented by Duncan Temple Lang for the
purpose of the \pkg{RObjectTables} package, allows for the dynamic symbol lookup.
Kenton Varda was generous with his time in reviewing code and explaining
obscure protocol buffer semantics.  Karl Millar was very
helpful in reviewing code and offering suggestions.  
%The contemporaneous work by Saptarshi Guha on \pkg{RHIPE} was a strong
%initial motivator.

\bibliography{article}

%\section[About Java]{About \proglang{Java}}
%% Note: If there is markup in \(sub)section, then it has to be escape as above.

\end{document}

